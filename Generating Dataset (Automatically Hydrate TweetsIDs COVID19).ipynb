{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Generating Dataset ( Automatically Hydrate TweetsIDs COVID19).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RDzd7FUKFviv"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbVmAxxGHUjO"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-Zr5kB6wknZ"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeimRLrjwpRr",
        "outputId": "adbd58ab-01eb-4dd7-d99c-2a1cd74a1d05"
      },
      "source": [
        "#@title Set up Directory { run: \"auto\"}\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive \n",
        "from IPython.display import clear_output\n",
        "drive.mount('/content/gdrive')\n",
        "working_directory = 'My Drive/Sem8/COVID19_Tweets' #@param {type:\"string\"}\n",
        "wd=\"/content/gdrive/\"+working_directory\n",
        "os.chdir(wd)\n",
        "\n",
        "dirpath = os.getcwd()\n",
        "print(\"current directory is : \" + dirpath)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "current directory is : /content/gdrive/.shortcut-targets-by-id/1_doUiOLFMGIDBhRxyDqTP0GhjehF9G6P/Sem8/COVID19_Tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_OfKAqTgNKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc596e95-fdac-4e59-d6ec-d0ac9307ffc4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDzd7FUKFviv"
      },
      "source": [
        "### Install twarc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvHm-ggFubK"
      },
      "source": [
        "%pip install twarc\n",
        "%pip install jsonlines\n",
        "%pip install wget\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gBPP8oJGDqM",
        "outputId": "e772a327-d45c-4a51-be6f-f29c4136aee6"
      },
      "source": [
        "#Check if TWARC was installed correctly on the Virtual Machine\n",
        "%pip show twarc\n",
        "%pip show jsonlines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: twarc\n",
            "Version: 2.0.13\n",
            "Summary: Archive tweets from the command line\n",
            "Home-page: https://github.com/docnow/twarc\n",
            "Author: Ed Summers\n",
            "Author-email: ehs@pobox.com\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: requests-oauthlib, python-dateutil, click, click-plugins, click-config-file\n",
            "Required-by: \n",
            "Name: jsonlines\n",
            "Version: 2.0.0\n",
            "Summary: Library with helpers for the jsonlines file format\n",
            "Home-page: https://github.com/wbolster/jsonlines\n",
            "Author: Wouter Bolsterlee\n",
            "Author-email: wouter@bolsterl.ee\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEsz47hdFHtW"
      },
      "source": [
        "### Twitter API Keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "et0_5DEEFNpW"
      },
      "source": [
        "#@title Insert API Keys here { run : \"auto\"}\n",
        "from twarc import Twarc\n",
        "\n",
        "# These keys are received after applying for a twitter developer account\n",
        "\n",
        "consumer_key = \"\" #@param {type:\"string\"}\n",
        "consumer_secret = \"\" #@param {type:\"string\"}\n",
        "access_token = \"\" #@param {type:\"string\"}\n",
        "access_token_secret = \"\" #@param {type:\"string\"}\n",
        "\n",
        "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyS66qo29K_g"
      },
      "source": [
        "### Download Github Files onto Drive for given dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZiHM582ReTh"
      },
      "source": [
        "You need to frist indicate the date range of file you would like to hydrate. Rememeber that the Start_date cannot be before 2020-01-22. If a incorrect end date is selected it will be not considered.  At the end you will see how many files you are requesting to download \n",
        "\n",
        "(it is assumed you want all hours from a given day, if you dont want some hour, you will need to deleted the hours you wont want).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeLOiUghTpKc",
        "outputId": "d97965f8-7372-4e34-b17e-14dbe3b0bb7b"
      },
      "source": [
        "#@title Date fields\n",
        "import pandas as pd\n",
        "Start_date = '2021-04-15' #@param {type:\"date\"}\n",
        "#@title Date fields\n",
        "End_date = '2021-04-15' #@param {type:\"date\"}\n",
        "\n",
        "\n",
        "\n",
        "datelist = pd.date_range(Start_date, End_date).tolist()\n",
        "number_files=0\n",
        "for date in datelist:\n",
        "  for h in ['00','01', '02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23']:\n",
        "    number_files=number_files+1\n",
        "\n",
        "print(\"You have requested to download a total of \"+ str(number_files) + ' files \\n The more files you download at once the longer it will take to upload to your Drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You have requested to download a total of 24 files \n",
            " The more files you download at once the longer it will take to upload to your Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VtnuqvTgIJO"
      },
      "source": [
        "The code below will create a new directory `Summary_Details_files` and save all the `.csv. files from the reposiory that were requested on that directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPbChi1mbVHv"
      },
      "source": [
        "\n",
        "from datetime import datetime\n",
        "import wget\n",
        "\n",
        "path = os.path.join(wd, \"Summary_Details_files\") \n",
        "if not os.path.exists('./Summary_Details_files'):\n",
        "  try:\n",
        "    os.makedirs(path)\n",
        "    os.chdir('Summary_Details_files')\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "datelist = pd.date_range(Start_date, End_date).tolist()\n",
        "files_list=[]\n",
        "for date in datelist:\n",
        "  day=date.strftime(\"%Y_%m_%d\")\n",
        "  p1=\"https://raw.githubusercontent.com/lopezbec/COVID19_Tweets_Dataset/master/Summary_Details/\"\n",
        "  m=day[0:7]\n",
        "  for h in ['00','01', '02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23']:\n",
        "    file=p1+m+\"/\"+day+\"_\"+str(h)+\"_Summary_Details.csv\"\n",
        "    wget.download(file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASdYyTqI9RUG"
      },
      "source": [
        "# Choose Settings Tweets_IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo52kGhpk69s"
      },
      "source": [
        "This are all the files you requested:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLREJkIRjvDh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "17aad313-7863-42ae-912a-aa5e43b55b60"
      },
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "\n",
        "Summary_Details=pd.DataFrame() \n",
        "directory =  os.getcwd()\n",
        "for root,dirs,files in os.walk(directory):\n",
        "  for file in files:\n",
        "    if file.endswith(\".csv\"):\n",
        "      data = pd.read_csv(file) \n",
        "      frames = [Summary_Details, data]\n",
        "      Summary_Details = pd.concat(frames)\n",
        "Summary_Details"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>Language</th>\n",
              "      <th>Geolocation_coordinate</th>\n",
              "      <th>RT</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Country</th>\n",
              "      <th>Date Created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1371250205094477825</td>\n",
              "      <td>ar</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:01:40 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1371251482595581955</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:06:44 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1371251959840309248</td>\n",
              "      <td>ar</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:08:38 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1371249785118859267</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>32161</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:00:00 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1371249785592639490</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>10864</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:00:00 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176934</th>\n",
              "      <td>1371612155666120704</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:59:55 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176935</th>\n",
              "      <td>1371612163882766337</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:59:57 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176936</th>\n",
              "      <td>1371612168538439683</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:59:58 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176937</th>\n",
              "      <td>1371612171541622788</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:59:59 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176938</th>\n",
              "      <td>1371612172254580738</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>2286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:59:59 +0000 2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3589601 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Tweet_ID Language  ... Country                    Date Created\n",
              "0       1371250205094477825       ar  ...     NaN  Mon Mar 15 00:01:40 +0000 2021\n",
              "1       1371251482595581955       en  ...     NaN  Mon Mar 15 00:06:44 +0000 2021\n",
              "2       1371251959840309248       ar  ...     NaN  Mon Mar 15 00:08:38 +0000 2021\n",
              "3       1371249785118859267       en  ...     NaN  Mon Mar 15 00:00:00 +0000 2021\n",
              "4       1371249785592639490       en  ...     NaN  Mon Mar 15 00:00:00 +0000 2021\n",
              "...                     ...      ...  ...     ...                             ...\n",
              "176934  1371612155666120704       en  ...     NaN  Mon Mar 15 23:59:55 +0000 2021\n",
              "176935  1371612163882766337       en  ...     NaN  Mon Mar 15 23:59:57 +0000 2021\n",
              "176936  1371612168538439683       en  ...     NaN  Mon Mar 15 23:59:58 +0000 2021\n",
              "176937  1371612171541622788       en  ...     NaN  Mon Mar 15 23:59:59 +0000 2021\n",
              "176938  1371612172254580738       en  ...     NaN  Mon Mar 15 23:59:59 +0000 2021\n",
              "\n",
              "[3589601 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0CfU-SUlUIp"
      },
      "source": [
        "### Filter Tweets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fj9ydtn9aIL"
      },
      "source": [
        "You can filter the tweets by:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qGdsBbsHxrcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "84ece94c-8f77-4c96-c456-f35ab689b104"
      },
      "source": [
        "\n",
        "Just_English_Tweets= True #@param {type:\"boolean\"}\n",
        "Just_with_Geolocation_information = False #@param {type:\"boolean\"}\n",
        "Just_Original_tweets = True #@param {type:\"boolean\"}\n",
        "Minimun_No_Likes =  5#@param {type:\"number\"}\n",
        "Minimun_No_Retweets =  0#@param {type:\"number\"}\n",
        "\n",
        "Summary_Details2=Summary_Details\n",
        "if(Just_English_Tweets):\n",
        "  Summary_Details2=Summary_Details2[ Summary_Details2['Language']=='en']\n",
        "if(Just_with_Geolocation_information):\n",
        "  Summary_Details2=Summary_Details2[ Summary_Details2['Geolocation_coordinate']=='YES']\n",
        "if(Just_Original_tweets):\n",
        "  Summary_Details2=Summary_Details2[ Summary_Details2['RT']=='NO']\n",
        "\n",
        "\n",
        "Summary_Details2=Summary_Details2[ Summary_Details2['Likes']>=Minimun_No_Likes]\n",
        "Summary_Details2=Summary_Details2[ Summary_Details2['Retweets']>=Minimun_No_Retweets]\n",
        "\n",
        "Summary_Details2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>Language</th>\n",
              "      <th>Geolocation_coordinate</th>\n",
              "      <th>RT</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Country</th>\n",
              "      <th>Date Created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1371249788922994690</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:00:00 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>1371249805964500992</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>26</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:00:04 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1371249809101836291</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:00:05 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>1371249821932253196</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:00:08 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>1371249835014287362</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 00:00:11 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175968</th>\n",
              "      <td>1371610520776761350</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:53:26 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176110</th>\n",
              "      <td>1371610747088736260</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:54:20 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176350</th>\n",
              "      <td>1371611165231489027</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:55:59 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176872</th>\n",
              "      <td>1371612066331697157</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:59:34 +0000 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176923</th>\n",
              "      <td>1371612144677105666</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mon Mar 15 23:59:53 +0000 2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52429 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Tweet_ID Language  ... Country                    Date Created\n",
              "52      1371249788922994690       en  ...     NaN  Mon Mar 15 00:00:00 +0000 2021\n",
              "125     1371249805964500992       en  ...     NaN  Mon Mar 15 00:00:04 +0000 2021\n",
              "140     1371249809101836291       en  ...     NaN  Mon Mar 15 00:00:05 +0000 2021\n",
              "202     1371249821932253196       en  ...     NaN  Mon Mar 15 00:00:08 +0000 2021\n",
              "268     1371249835014287362       en  ...     NaN  Mon Mar 15 00:00:11 +0000 2021\n",
              "...                     ...      ...  ...     ...                             ...\n",
              "175968  1371610520776761350       en  ...     NaN  Mon Mar 15 23:53:26 +0000 2021\n",
              "176110  1371610747088736260       en  ...     NaN  Mon Mar 15 23:54:20 +0000 2021\n",
              "176350  1371611165231489027       en  ...     NaN  Mon Mar 15 23:55:59 +0000 2021\n",
              "176872  1371612066331697157       en  ...     NaN  Mon Mar 15 23:59:34 +0000 2021\n",
              "176923  1371612144677105666       en  ...     NaN  Mon Mar 15 23:59:53 +0000 2021\n",
              "\n",
              "[52429 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K81sHrmZtID9"
      },
      "source": [
        "For more personalized filtering you can modify the pandas dataframe directly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BDEuBH7LPTn"
      },
      "source": [
        "### Save configuration into a file\n",
        "All the IDs are read into a single set in the previous code block using the specified configuration. The ID Output file stores all the IDs in a single file so that the configuration blocks don't have to be run again. In case the program unexpectedly stops, you can just run the code for Initialization and then the code for Hydration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "y4EfPTrnLO0c"
      },
      "source": [
        "#@title Enter ID output file {run: \"auto\"}\n",
        "os.chdir(wd)\n",
        "final_tweet_ids_filename = \"final_ids.txt\" #@param {type: \"string\"}\n",
        "# The set of IDs is stored in this file.\n",
        "with open(final_tweet_ids_filename, \"w+\") as f:\n",
        "    for id in Summary_Details2['Tweet_ID']:\n",
        "        f.write('%s\\n' % id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxFa0jOTKbBw"
      },
      "source": [
        "# Hydrate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBBH-a4WK1JM"
      },
      "source": [
        "### Set up output file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U74uUnemI6h9"
      },
      "source": [
        "The final_tweet_ids_filename should be exactly the same as the ID output file from the Configuration block. If this file does not exist in the working directory, you have to re-run the Configuration block.\n",
        "\n",
        "Please also keep the output_filename the same in case the code is halted. That way, tweets already hydrated aren't re-hydrated for no reason. \n",
        "\n",
        "Also, please do not remove the .txt file created after running the Hydrate block until all the data is converted to a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9ATxyEfSLBK1"
      },
      "source": [
        "#@title Set up Directory { run: \"auto\"}\n",
        "final_tweet_ids_filename = \"final_ids.txt\" #@param {type: \"string\"}\n",
        "output_filename = \"mar2.csv\" #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG9cS-aoW0Wy"
      },
      "source": [
        "The time for this code will depend on how many tweets you want to “hydrate”. Also, be advise of the Tweet API limit, the code will “go to sleep” once the limit is reach and automatically continue. \n",
        "You can leave this code running in Google Colab for a max of 12hrs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFwYd7m58WR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c83f7e2-827d-42a3-b3ed-94c24597a69b"
      },
      "source": [
        "import jsonlines, json\n",
        "import twarc\n",
        "from twarc import Twarc\n",
        "\n",
        "t = twarc.Twarc(consumer_key = \"\",\n",
        "                consumer_secret = \"\",\n",
        "                access_token = \"\",\n",
        "                access_token_secret = \"\")\n",
        "# Stores hydrated tweets here as jsonl objects\n",
        "# Contains one json object per line\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".txt\"\n",
        "ids = []\n",
        "with open(final_tweet_ids_filename, \"r\") as ids_file:\n",
        "    ids = ids_file.read().split()\n",
        "hydrated_tweets = []\n",
        "ids_to_hydrate = set(ids)\n",
        "\n",
        "# Looks at the output file for already hydrated tweets\n",
        "if os.path.isfile(output_json_filename):\n",
        "    with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "        for i in reader.iter(type=dict, skip_invalid=True):\n",
        "            # These tweets have already been hydrated. So remove them from ids_to_hydrate\n",
        "            hydrated_tweets.append(i)\n",
        "            ids_to_hydrate.remove(i[\"id_str\"])\n",
        "print(\"Total IDs: \" + str(len(ids)) + \", IDs to hydrate: \" + str(len(ids_to_hydrate)))\n",
        "print(\"Hydrated: \" + str(len(hydrated_tweets)))\n",
        "\n",
        "count = len(hydrated_tweets)\n",
        "start_index = count # The index from where tweets haven't been saved to the output_json_file\n",
        "# Stores hydrated tweets to output_json_file every num_save iterations.\n",
        "num_save  = 1000\n",
        "\n",
        "# Now, use twarc and start hydrating\n",
        "for tweet in t.hydrate(ids_to_hydrate):\n",
        "    hydrated_tweets.append(tweet)\n",
        "    count += 1\n",
        "    # If num_save iterations have passed,\n",
        "    if (count % num_save) == 0:\n",
        "        # Open the output file\n",
        "        # NOTE: Even if the code stops during IO, only tweets from the current iteration are lost.\n",
        "        # Older tweets are preserved as the file is written in append mode.\n",
        "        with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "            print(\"Started IO\")\n",
        "            # Now write the tweets from start_index. The other tweets don't have to be written\n",
        "            # as they were already written in a previous iteration or run.\n",
        "            for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "                writer.write(hydrated_tweet)\n",
        "            print(\"Finished IO\")\n",
        "        print(\"Saved \" + str(count) + \" hydrated tweets.\")\n",
        "        # Now, since everything has been written. Reset start_index\n",
        "        start_index = count\n",
        "# There might be tweets unwritten in the last iteration if the count is not a multiple of num_tweets.\n",
        "# In that case, just write out the remainder of tweets.\n",
        "if count != start_index:\n",
        "    print(\"Here with start_index\", start_index)\n",
        "    with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "        for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "           writer.write(hydrated_tweet)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total IDs: 52429, IDs to hydrate: 52429\n",
            "Hydrated: 0\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 1000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 2000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 3000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 4000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 5000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 6000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 7000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 8000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 9000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 10000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 11000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 12000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 13000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 14000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 15000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 16000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 17000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 18000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 19000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 20000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 21000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 22000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 23000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 24000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 25000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 26000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 27000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 28000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 29000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 30000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 31000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 32000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 33000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 34000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 35000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 36000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 37000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 38000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 39000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 40000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 41000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 42000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 43000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 44000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 45000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 46000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 47000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 48000 hydrated tweets.\n",
            "Started IO\n",
            "Finished IO\n",
            "Saved 49000 hydrated tweets.\n",
            "Here with start_index 49000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6O-KWKnbcGt"
      },
      "source": [
        "## Convert JSONL to CSV\n",
        "Data is stored in  output_json_file from the previous code block. This now converts the jsonl .txt file into a csv file. Note that the column names required is stored as a list in the code.\n",
        "\n",
        "Note that a few of the columns are actually json objects (for example, user or entities). You will have to clean these objects into 1D data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x68cvh5AJCD"
      },
      "source": [
        "# Convert jsonl to csv\n",
        "import csv, jsonlines\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".txt\"\n",
        "# These are the column name that are selected to be stored in the csv\n",
        "keyset = [\"created_at\", \"id\", \"id_str\", \"full_text\", \"source\", \"truncated\", \"in_reply_to_status_id\",\n",
        "          \"in_reply_to_status_id_str\", \"in_reply_to_user_id\", \"in_reply_to_user_id_str\", \n",
        "          \"in_reply_to_screen_name\", \"user\", \"coordinates\", \"place\", \"quoted_status_id\",\n",
        "          \"quoted_status_id_str\", \"is_quote_status\", \"quoted_status\", \"retweeted_status\", \n",
        "          \"quote_count\", \"reply_count\", \"retweet_count\", \"favorite_count\", \"entities\", \n",
        "          \"extended_entities\", \"favorited\", \"retweeted\", \"possibly_sensitive\", \"filter_level\", \n",
        "          \"lang\", \"matching_rules\", \"current_user_retweet\", \"scopes\", \"withheld_copyright\", \n",
        "          \"withheld_in_countries\", \"withheld_scope\", \"geo\", \"contributors\", \"display_text_range\",\n",
        "          \"quoted_status_permalink\"]\n",
        "hydrated_tweets = []\n",
        "# Reads the current tweets\n",
        "with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "    for i in reader.iter(type=dict, skip_invalid=True):\n",
        "        hydrated_tweets.append(i)\n",
        "# Writes them out\n",
        "with  open(output_filename, \"w+\") as output_file:\n",
        "    d = csv.DictWriter(output_file, keyset)\n",
        "    d.writeheader()\n",
        "    d.writerows(hydrated_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}